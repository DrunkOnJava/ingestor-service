#!/bin/bash
set -eo pipefail

# ========================================
# Ingestor - Content processing system
# 
# A CLI tool for processing various content types
# and storing extracted data in SQLite databases
# using Claude AI for intelligent processing.
# ========================================

# Version
INGESTOR_VERSION="0.1.0"

# Base paths
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
INGESTOR_HOME="${HOME}/.ingestor"
TEMP_DIR="${INGESTOR_HOME}/tmp"
CONFIG_DIR="${INGESTOR_HOME}/config"
DB_DIR="${INGESTOR_HOME}/databases"
LOG_DIR="${INGESTOR_HOME}/logs"

# Import modules - adjust paths as needed
source "${PROJECT_ROOT}/src/modules/logging.sh"      # Import logging first so other modules can use it
source "${PROJECT_ROOT}/src/modules/keychain.sh"     # Import keychain for credential management
source "${PROJECT_ROOT}/src/modules/config.sh"       # Config depends on keychain
source "${PROJECT_ROOT}/src/modules/content.sh"
source "${PROJECT_ROOT}/src/modules/database.sh"
source "${PROJECT_ROOT}/src/modules/claude.sh"
source "${PROJECT_ROOT}/src/modules/credentials.sh"  # Credential management functionality

# Initialize environment
setup_environment() {
    # Create necessary directories
    mkdir -p "${TEMP_DIR}" "${CONFIG_DIR}" "${DB_DIR}" "${LOG_DIR}"
    
    # Initialize logging
    init_logging
    
    # Load configuration
    load_config
    
    # Setup keychain credentials if keychain is available
    if keychain_available; then
        if [[ "$MODE" == "interactive" ]]; then
            # Only prompt for credentials in interactive mode
            setup_keychain_credentials
        fi
    else
        log_warning "Keychain is not available. Credentials will not be stored securely."
    fi
    
    # Setup cleanup trap
    trap cleanup EXIT INT TERM
    
    log_info "Ingestor v${INGESTOR_VERSION} initialized"
}

# Cleanup function
cleanup() {
    log_info "Cleaning up temporary files"
    rm -rf "${TEMP_DIR:?}"/*
    log_info "Ingestor session ended"
}

# Show help
show_help() {
    cat << EOF
Ingestor v${INGESTOR_VERSION} - Content processing system

Usage: ingestor [OPTIONS]

Options:
  --database, -d DB_NAME       Specify database to use
  --file, -f FILE_PATH         Process a specific file
  
  Batch Mode Options:
  --batch, -b                  Run in batch mode
  --directory, -dir PATH       Directory containing files to process
  --extensions, -ext PATTERN   File extensions to process (default: "*")
  --recursive, -r              Process directories recursively
  --max-files, -m NUMBER       Maximum number of files to process (0 = unlimited)
  
  Chunking Options:
  --enable-chunking, -ec       Enable content chunking (default)
  --disable-chunking, -dc      Disable content chunking
  --chunk-size, -cs SIZE       Size of each chunk in bytes (default: 500000)
  --chunk-overlap, -co SIZE    Overlap between chunks in bytes (default: 5000)
  --chunk-strategy, -cst STRAT Chunking strategy (size, paragraph, sentence)
  
  Credential Management:
  --manage-credentials, -mc    Interactive credential management menu
  --set-api-key, -sak KEY      Set Claude API key
  --keychain, -k               Store credentials in system keychain
  
  Other Options:
  --config, -c CONFIG          Use specific configuration file
  --list-dbs, -l               List available databases
  --init-db, -i DB_NAME        Initialize a new database
  --verbose, -v                Enable verbose logging
  --help, -h                   Show this help message

Examples:
  ingestor -d research                                # Interactive mode with research database
  ingestor -f image.jpg -d media                      # Process image.jpg into media database
  ingestor -b -dir ./documents -d research            # Process all files in ./documents
  ingestor -b -dir ./images -ext "*.jpg" -d media     # Process only JPG files in ./images
  ingestor -b -dir ./code -ext "*.py" -r -d code      # Process Python files recursively
  ingestor -f large_text.txt -d research -cs 250000   # Process with smaller chunks
  ingestor -f code.py -d code -cst paragraph          # Chunk by paragraphs
  ingestor -mc                                        # Manage credentials interactively
  ingestor -sak "your_api_key" -k                     # Store API key securely in keychain

For more information, visit: https://github.com/yourusername/ingestor
EOF
}

# Process command line arguments
process_arguments() {
    DATABASE=""
    MODE="interactive"
    FILE_PATH=""
    DIRECTORY_PATH=""
    FILE_EXTENSIONS="*"
    RECURSIVE=false
    MAX_FILES=0  # 0 means process all files
    VERBOSE=false
    
    # Default chunking settings
    ENABLE_CHUNKING=true  # Enable by default
    CHUNK_SIZE=500000     # Default ~500KB chunks
    CHUNK_OVERLAP=5000    # Default ~5KB overlap
    CHUNK_STRATEGY="size" # Possible values: size, paragraph, sentence
    
    # Credential management
    API_KEY_VALUE=""
    SET_API_KEY=false
    USE_KEYCHAIN=false
    
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --database|-d)
                DATABASE="$2"
                shift 2
                ;;
            --file|-f)
                MODE="file"
                FILE_PATH="$2"
                shift 2
                ;;
            --batch|-b)
                MODE="batch"
                shift
                ;;
            --directory|-dir)
                DIRECTORY_PATH="$2"
                shift 2
                ;;
            --extensions|-ext)
                FILE_EXTENSIONS="$2"
                shift 2
                ;;
            --recursive|-r)
                RECURSIVE=true
                shift
                ;;
            --max-files|-m)
                MAX_FILES="$2"
                shift 2
                ;;
            # Chunking options
            --enable-chunking|-ec)
                ENABLE_CHUNKING=true
                shift
                ;;
            --disable-chunking|-dc)
                ENABLE_CHUNKING=false
                shift
                ;;
            --chunk-size|-cs)
                CHUNK_SIZE="$2"
                shift 2
                ;;
            --chunk-overlap|-co)
                CHUNK_OVERLAP="$2"
                shift 2
                ;;
            --chunk-strategy|-cst)
                CHUNK_STRATEGY="$2"
                shift 2
                ;;
            # Credential management
            --manage-credentials|-mc)
                MODE="manage-credentials"
                shift
                ;;
            --set-api-key|-sak)
                API_KEY_VALUE="$2"
                SET_API_KEY=true
                shift 2
                ;;
            --keychain|-k)
                USE_KEYCHAIN=true
                shift
                ;;
            # Other options
            --config|-c)
                CONFIG_FILE="$2"
                shift 2
                ;;
            --list-dbs|-l)
                MODE="list-dbs"
                shift
                ;;
            --init-db|-i)
                MODE="init-db"
                DB_NAME="$2"
                shift 2
                ;;
            --verbose|-v)
                VERBOSE=true
                shift
                ;;
            --help|-h)
                show_help
                exit 0
                ;;
            *)
                log_error "Unknown option: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    # Check requirements based on mode
    if [[ "$MODE" != "list-dbs" && "$MODE" != "help" && "$MODE" != "manage-credentials" && -z "$DATABASE" ]]; then
        if [[ "$MODE" != "init-db" ]]; then
            log_error "Database name is required. Use --database option."
            exit 1
        fi
    fi
    
    if [[ "$MODE" = "file" && -z "$FILE_PATH" ]]; then
        log_error "File path is required for file mode. Use --file option."
        exit 1
    fi
    
    if [[ "$MODE" = "batch" && -z "$DIRECTORY_PATH" ]]; then
        log_error "Directory path is required for batch mode. Use --directory option."
        exit 1
    fi
    
    # Handle API key setting separately
    if [[ "$SET_API_KEY" = true && -z "$API_KEY_VALUE" ]]; then
        log_error "API key value is required when using --set-api-key option."
        exit 1
    fi
}

# Run interactive input mode
run_interactive_mode() {
    log_info "Starting interactive mode with database: $DATABASE"
    
    echo "=== Ingestor Interactive Mode ==="
    echo "Using database: $DATABASE"
    echo "Paste or type content, end with CTRL+D (EOF)"
    
    # Create temp file for input
    local temp_file="${TEMP_DIR}/interactive_input_$(date +%s).tmp"
    
    # Collect input until EOF
    cat > "$temp_file"
    
    # Process the collected input
    process_content "$temp_file" "$DATABASE"
    
    # Cleanup
    rm -f "$temp_file"
}

# Process a specific file
process_file() {
    local file_path="$1"
    local database="$2"
    
    if [[ ! -f "$file_path" ]]; then
        log_error "File not found: $file_path"
        return 1
    fi
    
    log_info "Processing file: $file_path for database: $database"
    
    # Detect content type and process accordingly
    local content_type
    content_type=$(detect_content_type "$file_path")
    
    if [[ -z "$content_type" ]]; then
        log_error "Failed to detect content type for: $file_path"
        return 1
    fi
    
    log_info "Detected content type: $content_type"
    log_info "Using chunking settings: enabled=$ENABLE_CHUNKING, size=$CHUNK_SIZE, overlap=$CHUNK_OVERLAP, strategy=$CHUNK_STRATEGY"
    
    # Process based on content type with chunking settings
    if process_content "$file_path" "$database" "$ENABLE_CHUNKING" "$CHUNK_SIZE" "$CHUNK_OVERLAP" "$CHUNK_STRATEGY"; then
        log_info "File processing completed successfully: $file_path"
        return 0
    else
        log_error "File processing failed: $file_path"
        return 1
    fi
}

# Process files in batch mode
run_batch_mode() {
    local directory_path="$1"
    local database="$2"
    local file_pattern="${3:-*}"
    local recursive="$4"
    local max_files="$5"
    
    if [[ ! -d "$directory_path" ]]; then
        log_error "Directory not found: $directory_path"
        exit 1
    fi
    
    log_info "Starting batch processing from directory: $directory_path"
    log_info "Using database: $database"
    log_info "File pattern: $file_pattern"
    log_info "Recursive mode: ${recursive:-false}"
    if [[ $max_files -gt 0 ]]; then
        log_info "Maximum files to process: $max_files"
    else
        log_info "Processing all matching files"
    fi
    
    # Prepare find command based on recursive flag
    local find_cmd
    if [[ "$recursive" == "true" ]]; then
        find_cmd="find \"$directory_path\" -type f -name \"$file_pattern\""
    else
        find_cmd="find \"$directory_path\" -maxdepth 1 -type f -name \"$file_pattern\""
    fi
    
    # Add sorting by modification time (newest first)
    find_cmd="$find_cmd -printf '%T@ %p\n' | sort -nr | cut -d' ' -f2-"
    
    # Add limit if max_files is set
    if [[ $max_files -gt 0 ]]; then
        find_cmd="$find_cmd | head -n $max_files"
    fi
    
    log_debug "Find command: $find_cmd"
    
    # Execute find command and store results
    local files_to_process
    files_to_process=$(eval "$find_cmd")
    
    # Count files
    local file_count
    file_count=$(echo "$files_to_process" | wc -l)
    
    if [[ -z "$files_to_process" ]]; then
        log_warning "No files found matching pattern: $file_pattern"
        exit 0
    fi
    
    log_info "Found $file_count files to process"
    
    # Process each file
    local processed=0
    local skipped=0
    local failed=0
    
    echo "==========================================="
    echo "Batch Processing: $file_count files"
    echo "==========================================="
    
    while IFS= read -r file_path; do
        if [[ -z "$file_path" ]]; then
            continue
        fi
        
        echo "Processing ($((processed + 1))/$file_count): $(basename "$file_path")"
        
        # Check if file exists and is readable
        if [[ ! -f "$file_path" || ! -r "$file_path" ]]; then
            log_warning "Skipping inaccessible file: $file_path"
            skipped=$((skipped + 1))
            continue
        fi
        
        # Process the file
        if process_file "$file_path" "$database"; then
            processed=$((processed + 1))
            echo "✓ Processed: $file_path"
        else
            failed=$((failed + 1))
            echo "✗ Failed: $file_path"
        fi
        
        echo "-----------------------------------------"
    done <<< "$files_to_process"
    
    echo "==========================================="
    echo "Batch Processing Summary"
    echo "==========================================="
    echo "Total files found:  $file_count"
    echo "Successfully processed: $processed"
    echo "Failed: $failed"
    echo "Skipped: $skipped"
    echo "==========================================="
    
    log_info "Batch processing completed"
}

# List available databases
list_databases() {
    log_info "Listing available databases"
    
    echo "Available Databases:"
    echo "-------------------"
    
    if [[ -d "$DB_DIR" ]]; then
        local count=0
        
        for db in "$DB_DIR"/*.sqlite; do
            if [[ -f "$db" ]]; then
                local db_name=$(basename "$db" .sqlite)
                local tables=$(sqlite3 "$db" ".tables")
                local size=$(du -h "$db" | cut -f1)
                
                echo "- $db_name (Size: $size)"
                echo "  Tables: $tables"
                echo
                
                count=$((count + 1))
            fi
        done
        
        if [[ $count -eq 0 ]]; then
            echo "No databases found."
        fi
    else
        echo "No databases found."
    fi
}

# Initialize a new database
init_database_cli() {
    local db_name="$1"
    
    log_info "Initializing new database: $db_name"
    
    if [[ -f "${DB_DIR}/${db_name}.sqlite" ]]; then
        read -p "Database already exists. Overwrite? (y/N): " confirm
        if [[ ! "$confirm" =~ ^[Yy] ]]; then
            log_info "Database initialization cancelled"
            return 1
        fi
    fi
    
    # Select database type
    echo "Select database type:"
    echo "1. General Content"
    echo "2. Media (Images/Videos)"
    echo "3. Code Repository"
    echo "4. Research/Papers"
    echo "5. Custom Schema"
    
    read -p "Selection (1-5): " db_type
    
    case "$db_type" in
        1) schema_file="${PROJECT_ROOT}/config/schemas/general.sql" ;;
        2) schema_file="${PROJECT_ROOT}/config/schemas/media.sql" ;;
        3) schema_file="${PROJECT_ROOT}/config/schemas/code.sql" ;;
        4) schema_file="${PROJECT_ROOT}/config/schemas/research.sql" ;;
        5)
            read -p "Path to custom schema file: " schema_file
            if [[ ! -f "$schema_file" ]]; then
                log_error "Schema file not found: $schema_file"
                return 1
            fi
            ;;
        *)
            log_error "Invalid selection"
            return 1
            ;;
    esac
    
    # Initialize database with schema
    init_database "${DB_DIR}/${db_name}.sqlite" "$schema_file"
    
    log_info "Database initialized: ${db_name}"
    echo "Database '${db_name}' initialized successfully."
}

# Main entry point with workflow orchestration
main() {
    # Process arguments first for early validation
    process_arguments "$@"
    
    # Special case: if setting API key directly, do it before loading configs
    if [[ "$SET_API_KEY" = true && -n "$API_KEY_VALUE" ]]; then
        if [[ "$USE_KEYCHAIN" = true ]]; then
            # Initialize basic logging without full environment
            init_logging
            
            if ! keychain_available; then
                log_error "Keychain is not available on this system, cannot store API key in keychain."
                exit 1
            fi
            
            if store_keychain_credential "claude_api_key" "$API_KEY_VALUE"; then
                echo "Claude API key stored successfully in keychain."
                # Update config to use keychain
                if [[ -f "$CONFIG_FILE" ]]; then
                    update_config_for_keychain
                fi
                exit 0
            else
                log_error "Failed to store Claude API key in keychain."
                exit 1
            fi
        else
            # Simply write to the config file
            # Make sure config directory exists
            mkdir -p "$CONFIG_DIR"
            
            # Check if config exists, if not create it first
            if [[ ! -f "$CONFIG_FILE" ]]; then
                # Initialize basic logging
                init_logging
                create_default_config
            fi
            
            # Now update the config with the provided API key
            store_key_in_config "$API_KEY_VALUE"
            echo "Claude API key set in configuration file."
            exit 0
        fi
    fi
    
    # Set up the environment for normal operation
    setup_environment
    
    case "$MODE" in
        interactive)
            run_interactive_mode
            ;;
        file)
            process_file "$FILE_PATH" "$DATABASE"
            ;;
        batch)
            run_batch_mode "$DIRECTORY_PATH" "$DATABASE" "$FILE_EXTENSIONS" "$RECURSIVE" "$MAX_FILES"
            ;;
        list-dbs)
            list_databases
            ;;
        init-db)
            init_database_cli "$DB_NAME"
            ;;
        manage-credentials)
            manage_credentials_interactive
            ;;
    esac
}

# Start the program
main "$@"